{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c1932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification model using TF 2.0 to model the usefulness of gliomadf \n",
    "# Ref: https://stackabuse.com/tensorflow-2-0-solving-classification-and-regression-problems/\n",
    "# Data files of gliomadf: https://archive.ics.uci.edu/dataset/759/glioma+grading+clinical+and+mutation+features+dataset\n",
    "# Ref2 Book: Giancarlo Zaccone, Getting Started with TensorFlow-Packt Publishing (2016)\n",
    "# Chapter 3 on Classifiers \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Ref for matplotlib: https://www.tutorialspoint.com/matplotlib/index.htm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa849c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Grade', 'Gender', 'Age_at_diagnosis', 'Race', 'IDH1', 'TP53', 'ATRX',\n",
      "       'PTEN', 'EGFR', 'CIC', 'MUC16', 'PIK3CA', 'NF1', 'PIK3R1', 'FUBP1',\n",
      "       'RB1', 'NOTCH1', 'BCOR', 'CSMD3', 'SMARCA4', 'GRIN2A', 'IDH2', 'FAT4',\n",
      "       'PDGFRA'],\n",
      "      dtype='object')\n",
      "     Grade  Gender  Age_at_diagnosis  Race  IDH1  TP53  ATRX  PTEN  EGFR  CIC  \\\n",
      "0        0       0             51.30     0     1     0     0     0     0    0   \n",
      "1        0       0             38.72     0     1     0     0     0     0    1   \n",
      "2        0       0             35.17     0     1     1     1     0     0    0   \n",
      "3        0       1             32.78     0     1     1     1     0     0    0   \n",
      "4        0       0             31.51     0     1     1     1     0     0    0   \n",
      "..     ...     ...               ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "834      1       1             77.89     0     0     0     0     1     0    0   \n",
      "835      1       0             85.18     0     0     1     0     1     0    0   \n",
      "836      1       1             77.49     0     0     1     0     1     0    0   \n",
      "837      1       0             63.33     0     0     1     0     0     0    0   \n",
      "838      1       0             76.61     1     0     0     0     0     0    0   \n",
      "\n",
      "     ...  FUBP1  RB1  NOTCH1  BCOR  CSMD3  SMARCA4  GRIN2A  IDH2  FAT4  PDGFRA  \n",
      "0    ...      1    0       0     0      0        0       0     0     0       0  \n",
      "1    ...      0    0       0     0      0        0       0     0     0       0  \n",
      "2    ...      0    0       0     0      0        0       0     0     0       0  \n",
      "3    ...      0    0       0     0      0        0       0     0     1       0  \n",
      "4    ...      0    0       0     0      0        0       0     0     0       0  \n",
      "..   ...    ...  ...     ...   ...    ...      ...     ...   ...   ...     ...  \n",
      "834  ...      0    0       0     0      0        0       0     0     0       0  \n",
      "835  ...      0    0       0     0      0        0       0     0     0       0  \n",
      "836  ...      0    0       0     0      0        0       0     0     0       0  \n",
      "837  ...      0    1       0     0      0        0       0     0     0       0  \n",
      "838  ...      0    0       0     0      0        0       0     0     0       0  \n",
      "\n",
      "[839 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "gliomadf = pd.read_csv(\"TCGA_InfoWithGrade.csv\")\n",
    "print(gliomadf.columns)\n",
    "print(gliomadf) # A DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4b113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grade</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_at_diagnosis</th>\n",
       "      <th>Race</th>\n",
       "      <th>IDH1</th>\n",
       "      <th>TP53</th>\n",
       "      <th>ATRX</th>\n",
       "      <th>PTEN</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>CIC</th>\n",
       "      <th>...</th>\n",
       "      <th>FUBP1</th>\n",
       "      <th>RB1</th>\n",
       "      <th>NOTCH1</th>\n",
       "      <th>BCOR</th>\n",
       "      <th>CSMD3</th>\n",
       "      <th>SMARCA4</th>\n",
       "      <th>GRIN2A</th>\n",
       "      <th>IDH2</th>\n",
       "      <th>FAT4</th>\n",
       "      <th>PDGFRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>839 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Grade  Gender  Age_at_diagnosis  Race  IDH1  TP53  ATRX  PTEN  EGFR  CIC  \\\n",
       "0        0       0             51.30     0     1     0     0     0     0    0   \n",
       "1        0       0             38.72     0     1     0     0     0     0    1   \n",
       "2        0       0             35.17     0     1     1     1     0     0    0   \n",
       "3        0       1             32.78     0     1     1     1     0     0    0   \n",
       "4        0       0             31.51     0     1     1     1     0     0    0   \n",
       "..     ...     ...               ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "834      1       1             77.89     0     0     0     0     1     0    0   \n",
       "835      1       0             85.18     0     0     1     0     1     0    0   \n",
       "836      1       1             77.49     0     0     1     0     1     0    0   \n",
       "837      1       0             63.33     0     0     1     0     0     0    0   \n",
       "838      1       0             76.61     1     0     0     0     0     0    0   \n",
       "\n",
       "     ...  FUBP1  RB1  NOTCH1  BCOR  CSMD3  SMARCA4  GRIN2A  IDH2  FAT4  PDGFRA  \n",
       "0    ...      1    0       0     0      0        0       0     0     0       0  \n",
       "1    ...      0    0       0     0      0        0       0     0     0       0  \n",
       "2    ...      0    0       0     0      0        0       0     0     0       0  \n",
       "3    ...      0    0       0     0      0        0       0     0     1       0  \n",
       "4    ...      0    0       0     0      0        0       0     0     0       0  \n",
       "..   ...    ...  ...     ...   ...    ...      ...     ...   ...   ...     ...  \n",
       "834  ...      0    0       0     0      0        0       0     0     0       0  \n",
       "835  ...      0    0       0     0      0        0       0     0     0       0  \n",
       "836  ...      0    0       0     0      0        0       0     0     0       0  \n",
       "837  ...      0    1       0     0      0        0       0     0     0       0  \n",
       "838  ...      0    0       0     0      0        0       0     0     0       0  \n",
       "\n",
       "[839 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datal cols = ['Grade', 'Gender', 'Age_at_diagnosis', 'Race', 'IDH1', 'TP53', 'ATRX', 'PTEN', 'EGFR', 'CIC', 'MUC16', 'PIK3CA', 'NF1', 'PIK3R1', 'FUBP1', 'RB1', 'NOTCH1', 'BCOR', CSMD3', 'SMARCA4', 'GRIN2A', 'IDH2', 'FAT4', 'PDGFRA']\n",
    "\n",
    "cols = ['Grade', 'Gender', 'Age_at_diagnosis', 'Race', 'IDH1', 'TP53', 'ATRX',\n",
    "       'PTEN', 'EGFR', 'CIC', 'MUC16', 'PIK3CA', 'NF1', 'PIK3R1', 'FUBP1',\n",
    "       'RB1', 'NOTCH1', 'BCOR', 'CSMD3', 'SMARCA4', 'GRIN2A', 'IDH2', 'FAT4',\n",
    "       'PDGFRA']\n",
    "\n",
    "# # Import the CSV file to Panda's DataFrame format.\n",
    "# gliomadf = pd.read_csv(\"TCGA_InfoWithGrade\", names=cols, header=None)\n",
    "# print(cols)\n",
    "gliomadf # A DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c147bea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grade</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_at_diagnosis</th>\n",
       "      <th>Race</th>\n",
       "      <th>IDH1</th>\n",
       "      <th>TP53</th>\n",
       "      <th>ATRX</th>\n",
       "      <th>PTEN</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>CIC</th>\n",
       "      <th>...</th>\n",
       "      <th>FUBP1</th>\n",
       "      <th>RB1</th>\n",
       "      <th>NOTCH1</th>\n",
       "      <th>BCOR</th>\n",
       "      <th>CSMD3</th>\n",
       "      <th>SMARCA4</th>\n",
       "      <th>GRIN2A</th>\n",
       "      <th>IDH2</th>\n",
       "      <th>FAT4</th>\n",
       "      <th>PDGFRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grade  Gender  Age_at_diagnosis  Race  IDH1  TP53  ATRX  PTEN  EGFR  CIC  \\\n",
       "0      0       0             51.30     0     1     0     0     0     0    0   \n",
       "1      0       0             38.72     0     1     0     0     0     0    1   \n",
       "2      0       0             35.17     0     1     1     1     0     0    0   \n",
       "3      0       1             32.78     0     1     1     1     0     0    0   \n",
       "4      0       0             31.51     0     1     1     1     0     0    0   \n",
       "\n",
       "   ...  FUBP1  RB1  NOTCH1  BCOR  CSMD3  SMARCA4  GRIN2A  IDH2  FAT4  PDGFRA  \n",
       "0  ...      1    0       0     0      0        0       0     0     0       0  \n",
       "1  ...      0    0       0     0      0        0       0     0     0       0  \n",
       "2  ...      0    0       0     0      0        0       0     0     0       0  \n",
       "3  ...      0    0       0     0      0        0       0     0     1       0  \n",
       "4  ...      0    0       0     0      0        0       0     0     0       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gliomadf.drop_duplicates(inplace=True)\n",
    "gliomadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76726a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size = plt.rcParams[\"figure.figsize\"]\n",
    "plot_size [0] = 10 #8\n",
    "plot_size [1] = 10 #6\n",
    "plt.rcParams[\"figure.figsize\"] = plot_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d39c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Grade'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gliomadf.Grade.value_counts().plot(kind='pie', autopct='%0.05f%%', \\\n",
    "                                colors=['orange', 'lightgreen']) #, \\\n",
    "                                # explode=(0.05, 0.05, 0.05,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fda8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    486\n",
      "1    352\n",
      "Name: Grade, dtype: int64\n",
      "0    487\n",
      "1    351\n",
      "Name: Gender, dtype: int64\n",
      "58.04    3\n",
      "55.13    3\n",
      "41.32    3\n",
      "57.55    3\n",
      "64.82    3\n",
      "        ..\n",
      "31.95    1\n",
      "32.46    1\n",
      "44.36    1\n",
      "40.29    1\n",
      "76.61    1\n",
      "Name: Age_at_diagnosis, Length: 766, dtype: int64\n",
      "0    764\n",
      "1     59\n",
      "2     14\n",
      "3      1\n",
      "Name: Race, dtype: int64\n",
      "0    435\n",
      "1    403\n",
      "Name: IDH1, dtype: int64\n",
      "0    491\n",
      "1    347\n",
      "Name: TP53, dtype: int64\n",
      "0    622\n",
      "1    216\n",
      "Name: ATRX, dtype: int64\n",
      "0    697\n",
      "1    141\n",
      "Name: PTEN, dtype: int64\n",
      "0    726\n",
      "1    112\n",
      "Name: EGFR, dtype: int64\n",
      "0    727\n",
      "1    111\n",
      "Name: CIC, dtype: int64\n",
      "0    740\n",
      "1     98\n",
      "Name: MUC16, dtype: int64\n",
      "0    765\n",
      "1     73\n",
      "Name: PIK3CA, dtype: int64\n",
      "0    771\n",
      "1     67\n",
      "Name: NF1, dtype: int64\n",
      "0    784\n",
      "1     54\n",
      "Name: PIK3R1, dtype: int64\n",
      "0    793\n",
      "1     45\n",
      "Name: FUBP1, dtype: int64\n",
      "0    798\n",
      "1     40\n",
      "Name: RB1, dtype: int64\n",
      "0    800\n",
      "1     38\n",
      "Name: NOTCH1, dtype: int64\n",
      "0    809\n",
      "1     29\n",
      "Name: BCOR, dtype: int64\n",
      "0    811\n",
      "1     27\n",
      "Name: CSMD3, dtype: int64\n",
      "0    811\n",
      "1     27\n",
      "Name: SMARCA4, dtype: int64\n",
      "0    811\n",
      "1     27\n",
      "Name: GRIN2A, dtype: int64\n",
      "0    815\n",
      "1     23\n",
      "Name: IDH2, dtype: int64\n",
      "0    815\n",
      "1     23\n",
      "Name: FAT4, dtype: int64\n",
      "0    816\n",
      "1     22\n",
      "Name: PDGFRA, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in list(gliomadf):\n",
    "  print(gliomadf[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94700040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0    251\n",
      "10.0    224\n",
      "5.0     176\n",
      "20.0     93\n",
      "0.0      67\n",
      "25.0     20\n",
      "30.0      3\n",
      "85.0      2\n",
      "65.0      1\n",
      "45.0      1\n",
      "Name: Mutations, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grade</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_at_diagnosis</th>\n",
       "      <th>Race</th>\n",
       "      <th>IDH1</th>\n",
       "      <th>TP53</th>\n",
       "      <th>ATRX</th>\n",
       "      <th>PTEN</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>CIC</th>\n",
       "      <th>...</th>\n",
       "      <th>RB1</th>\n",
       "      <th>NOTCH1</th>\n",
       "      <th>BCOR</th>\n",
       "      <th>CSMD3</th>\n",
       "      <th>SMARCA4</th>\n",
       "      <th>GRIN2A</th>\n",
       "      <th>IDH2</th>\n",
       "      <th>FAT4</th>\n",
       "      <th>PDGFRA</th>\n",
       "      <th>Mutations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grade  Gender  Age_at_diagnosis  Race  IDH1  TP53  ATRX  PTEN  EGFR  CIC  \\\n",
       "0      0       0             51.30     0     1     0     0     0     0    0   \n",
       "1      0       0             38.72     0     1     0     0     0     0    1   \n",
       "2      0       0             35.17     0     1     1     1     0     0    0   \n",
       "3      0       1             32.78     0     1     1     1     0     0    0   \n",
       "4      0       0             31.51     0     1     1     1     0     0    0   \n",
       "\n",
       "   ...  RB1  NOTCH1  BCOR  CSMD3  SMARCA4  GRIN2A  IDH2  FAT4  PDGFRA  \\\n",
       "0  ...    0       0     0      0        0       0     0     0       0   \n",
       "1  ...    0       0     0      0        0       0     0     0       0   \n",
       "2  ...    0       0     0      0        0       0     0     0       0   \n",
       "3  ...    0       0     0      0        0       0     0     1       0   \n",
       "4  ...    0       0     0      0        0       0     0     0       0   \n",
       "\n",
       "   Mutations  \n",
       "0       15.0  \n",
       "1       10.0  \n",
       "2       15.0  \n",
       "3       30.0  \n",
       "4       15.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column for percentage of mutations\n",
    "gliomadf['Mutations'] = (gliomadf.loc[:, 'IDH1':'PDGFRA'].sum(axis=1) / 20) * 100\n",
    "print(gliomadf['Mutations'].value_counts())\n",
    "\n",
    "gliomadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e1b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grade</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_at_diagnosis</th>\n",
       "      <th>Race</th>\n",
       "      <th>IDH1</th>\n",
       "      <th>TP53</th>\n",
       "      <th>ATRX</th>\n",
       "      <th>PTEN</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>CIC</th>\n",
       "      <th>...</th>\n",
       "      <th>RB1</th>\n",
       "      <th>NOTCH1</th>\n",
       "      <th>BCOR</th>\n",
       "      <th>CSMD3</th>\n",
       "      <th>SMARCA4</th>\n",
       "      <th>GRIN2A</th>\n",
       "      <th>IDH2</th>\n",
       "      <th>FAT4</th>\n",
       "      <th>PDGFRA</th>\n",
       "      <th>Mutations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.779602</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.198796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.005819</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.158117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.499031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.239046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grade  Gender  Age_at_diagnosis  Race  IDH1  TP53  ATRX  PTEN  EGFR  CIC  \\\n",
       "0      0       0          0.022035     0     1     0     0     0     0    0   \n",
       "1      0       0         -0.779602     0     1     0     0     0     0    1   \n",
       "2      0       0         -1.005819     0     1     1     1     0     0    0   \n",
       "3      0       1         -1.158117     0     1     1     1     0     0    0   \n",
       "4      0       0         -1.239046     0     1     1     1     0     0    0   \n",
       "\n",
       "   ...  RB1  NOTCH1  BCOR  CSMD3  SMARCA4  GRIN2A  IDH2  FAT4  PDGFRA  \\\n",
       "0  ...    0       0     0      0        0       0     0     0       0   \n",
       "1  ...    0       0     0      0        0       0     0     0       0   \n",
       "2  ...    0       0     0      0        0       0     0     0       0   \n",
       "3  ...    0       0     0      0        0       0     0     1       0   \n",
       "4  ...    0       0     0      0        0       0     0     0       0   \n",
       "\n",
       "   Mutations  \n",
       "0   0.475661  \n",
       "1  -0.198796  \n",
       "2   0.475661  \n",
       "3   2.499031  \n",
       "4   0.475661  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalise Age and percentage of Mutation columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "gliomadf[['Age_at_diagnosis']]=sc.fit_transform(gliomadf[['Age_at_diagnosis']])\n",
    "gliomadf[['Mutations']]=sc.fit_transform(gliomadf[['Mutations']])\n",
    "gliomadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e425eeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(838, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_at_diagnosis</th>\n",
       "      <th>IDH1</th>\n",
       "      <th>TP53</th>\n",
       "      <th>ATRX</th>\n",
       "      <th>PTEN</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>CIC</th>\n",
       "      <th>MUC16</th>\n",
       "      <th>PIK3CA</th>\n",
       "      <th>...</th>\n",
       "      <th>RB1</th>\n",
       "      <th>NOTCH1</th>\n",
       "      <th>BCOR</th>\n",
       "      <th>CSMD3</th>\n",
       "      <th>SMARCA4</th>\n",
       "      <th>GRIN2A</th>\n",
       "      <th>IDH2</th>\n",
       "      <th>FAT4</th>\n",
       "      <th>PDGFRA</th>\n",
       "      <th>Mutations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.779602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.198796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.005819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.158117</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.499031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.239046</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>1</td>\n",
       "      <td>1.716432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.873252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0</td>\n",
       "      <td>2.180974</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.198796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>1</td>\n",
       "      <td>1.690943</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.198796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>0</td>\n",
       "      <td>0.788624</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.150117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>0</td>\n",
       "      <td>1.634867</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.547709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>838 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Age_at_diagnosis  IDH1  TP53  ATRX  PTEN  EGFR  CIC  MUC16  \\\n",
       "0         0          0.022035     1     0     0     0     0    0      0   \n",
       "1         0         -0.779602     1     0     0     0     0    1      0   \n",
       "2         0         -1.005819     1     1     1     0     0    0      0   \n",
       "3         1         -1.158117     1     1     1     0     0    0      1   \n",
       "4         0         -1.239046     1     1     1     0     0    0      0   \n",
       "..      ...               ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "834       1          1.716432     0     0     0     1     0    0      0   \n",
       "835       0          2.180974     0     1     0     1     0    0      0   \n",
       "836       1          1.690943     0     1     0     1     0    0      0   \n",
       "837       0          0.788624     0     1     0     0     0    0      1   \n",
       "838       0          1.634867     0     0     0     0     0    0      0   \n",
       "\n",
       "     PIK3CA  ...  RB1  NOTCH1  BCOR  CSMD3  SMARCA4  GRIN2A  IDH2  FAT4  \\\n",
       "0         1  ...    0       0     0      0        0       0     0     0   \n",
       "1         0  ...    0       0     0      0        0       0     0     0   \n",
       "2         0  ...    0       0     0      0        0       0     0     0   \n",
       "3         0  ...    0       0     0      0        0       0     0     1   \n",
       "4         0  ...    0       0     0      0        0       0     0     0   \n",
       "..      ...  ...  ...     ...   ...    ...      ...     ...   ...   ...   \n",
       "834       0  ...    0       0     0      0        0       0     0     0   \n",
       "835       0  ...    0       0     0      0        0       0     0     0   \n",
       "836       0  ...    0       0     0      0        0       0     0     0   \n",
       "837       1  ...    1       0     0      0        0       0     0     0   \n",
       "838       0  ...    0       0     0      0        0       0     0     0   \n",
       "\n",
       "     PDGFRA  Mutations  \n",
       "0         0   0.475661  \n",
       "1         0  -0.198796  \n",
       "2         0   0.475661  \n",
       "3         0   2.499031  \n",
       "4         0   0.475661  \n",
       "..      ...        ...  \n",
       "834       0  -0.873252  \n",
       "835       0  -0.198796  \n",
       "836       0  -0.198796  \n",
       "837       0   1.150117  \n",
       "838       0  -1.547709  \n",
       "\n",
       "[838 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = gliomadf[['Gender', 'Age_at_diagnosis', 'IDH1', 'TP53', 'ATRX', 'PTEN', 'EGFR', 'CIC', 'MUC16', 'PIK3CA', 'NF1', 'PIK3R1', 'FUBP1',\n",
    "       'RB1', 'NOTCH1', 'BCOR', 'CSMD3', 'SMARCA4', 'GRIN2A', 'IDH2', 'FAT4', 'PDGFRA', 'Mutations']]\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f770873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    486\n",
       "1    352\n",
       "Name: Grade, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = gliomadf['Grade']\n",
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5ce0238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "y = labels.values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3c912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(838, 23)\n",
      "(838,)\n",
      "Shape of X_train and X_test: (645, 23) (193, 23)\n",
      "Shape of y_train and y_test: (645,) (193,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# random_state is a seed. It can be any value. If we keep it same on every\n",
    "# run, then there will be repeatability in the results.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.23, \n",
    "                                                    random_state=40)\n",
    "print('Shape of X_train and X_test:', X_train.shape, X_test.shape)\n",
    "print('Shape of y_train and y_test:', y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf1dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of nodes in each layer of the network\n",
    "DENSE1_SIZE = 22\n",
    "DENSE2_SIZE = 16\n",
    "DENSE3_SIZE = 8\n",
    "NUM_OF_EPOCHS = 100 \n",
    "BATCH_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d745df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# gliomadf_dataset:\n",
    "input_shape = X.shape[1]\n",
    "print(input_shape)\n",
    "model.add(tf.keras.layers.Flatten(input_shape =(input_shape,)))\n",
    "# if DENSE1_SIZE = 22, total no. of params: 22*23 weights = 506 + 22 biases = 528\n",
    "model.add(tf.keras.layers.Dense(DENSE1_SIZE, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(DENSE2_SIZE, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(DENSE3_SIZE, activation='relu'))\n",
    "# Output labels: 0 / 1\n",
    "# So, no. of output categories = 1 (LGG or GBM)\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Adam: Adaptive Moment Estimator (a stochastic optimization algorithm)\n",
    "# Which maintains per parameter leraning rate (LR) using momemnts (rate of change of LR)\n",
    "# Useful in the system where the classification features are more and noisy\n",
    "# Ref: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "# Crossentropy loss fn is used when there are two or more label classes.\n",
    "# The labels are expected to be provided in a one_hot representation.\n",
    "# One hot encoding: It represents categorical variables as binary vectors.\n",
    "# To represent a particular label, mark it as 1 and all other labels as zeros\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21f85e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 23)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 22)                528       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                368       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,041\n",
      "Trainable params: 1,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77dde18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 20ms/step - loss: 0.7226 - acc: 0.4493 - val_loss: 0.6775 - val_acc: 0.6479\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.6271 - acc: 0.7416 - val_loss: 0.5833 - val_acc: 0.8451\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5136 - acc: 0.8330 - val_loss: 0.4311 - val_acc: 0.8592\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3996 - acc: 0.8489 - val_loss: 0.3622 - val_acc: 0.8662\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.3636 - acc: 0.8588 - val_loss: 0.3540 - val_acc: 0.8732\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3501 - acc: 0.8648 - val_loss: 0.3492 - val_acc: 0.8803\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3405 - acc: 0.8668 - val_loss: 0.3507 - val_acc: 0.8803\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3308 - acc: 0.8668 - val_loss: 0.3476 - val_acc: 0.8873\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3251 - acc: 0.8688 - val_loss: 0.3491 - val_acc: 0.9014\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.3176 - acc: 0.8748 - val_loss: 0.3491 - val_acc: 0.9014\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3129 - acc: 0.8787 - val_loss: 0.3498 - val_acc: 0.9085\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3098 - acc: 0.8748 - val_loss: 0.3474 - val_acc: 0.8944\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3065 - acc: 0.8767 - val_loss: 0.3525 - val_acc: 0.9085\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3022 - acc: 0.8748 - val_loss: 0.3526 - val_acc: 0.9014\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2972 - acc: 0.8787 - val_loss: 0.3578 - val_acc: 0.9085\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2940 - acc: 0.8787 - val_loss: 0.3648 - val_acc: 0.9085\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2899 - acc: 0.8807 - val_loss: 0.3676 - val_acc: 0.9085\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2872 - acc: 0.8827 - val_loss: 0.3678 - val_acc: 0.9085\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2846 - acc: 0.8787 - val_loss: 0.3669 - val_acc: 0.9014\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2810 - acc: 0.8827 - val_loss: 0.3738 - val_acc: 0.9014\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2770 - acc: 0.8847 - val_loss: 0.3784 - val_acc: 0.9014\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2740 - acc: 0.8907 - val_loss: 0.3806 - val_acc: 0.9014\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2732 - acc: 0.8807 - val_loss: 0.3827 - val_acc: 0.9014\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2701 - acc: 0.8827 - val_loss: 0.3882 - val_acc: 0.8944\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2679 - acc: 0.8867 - val_loss: 0.3846 - val_acc: 0.9014\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2653 - acc: 0.8926 - val_loss: 0.3991 - val_acc: 0.9085\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2651 - acc: 0.8907 - val_loss: 0.3952 - val_acc: 0.8944\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2600 - acc: 0.8807 - val_loss: 0.4031 - val_acc: 0.8944\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2592 - acc: 0.8907 - val_loss: 0.4127 - val_acc: 0.9014\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2549 - acc: 0.8926 - val_loss: 0.4172 - val_acc: 0.8944\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2566 - acc: 0.8926 - val_loss: 0.4116 - val_acc: 0.8944\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2559 - acc: 0.8827 - val_loss: 0.4306 - val_acc: 0.9014\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2504 - acc: 0.8966 - val_loss: 0.4280 - val_acc: 0.8944\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2476 - acc: 0.8926 - val_loss: 0.4269 - val_acc: 0.8944\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2456 - acc: 0.8986 - val_loss: 0.4423 - val_acc: 0.8944\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2443 - acc: 0.8986 - val_loss: 0.4389 - val_acc: 0.8944\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2430 - acc: 0.8966 - val_loss: 0.4527 - val_acc: 0.8803\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2405 - acc: 0.8966 - val_loss: 0.4597 - val_acc: 0.8873\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2403 - acc: 0.8966 - val_loss: 0.4534 - val_acc: 0.8944\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2372 - acc: 0.9006 - val_loss: 0.4626 - val_acc: 0.8873\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2353 - acc: 0.8986 - val_loss: 0.4623 - val_acc: 0.8944\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2330 - acc: 0.9026 - val_loss: 0.4663 - val_acc: 0.9014\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2320 - acc: 0.9026 - val_loss: 0.4748 - val_acc: 0.8803\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2348 - acc: 0.9046 - val_loss: 0.4725 - val_acc: 0.9014\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2311 - acc: 0.9046 - val_loss: 0.4884 - val_acc: 0.8944\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2296 - acc: 0.9085 - val_loss: 0.4874 - val_acc: 0.8873\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2276 - acc: 0.9105 - val_loss: 0.5016 - val_acc: 0.8662\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2318 - acc: 0.9066 - val_loss: 0.5086 - val_acc: 0.8662\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2279 - acc: 0.9046 - val_loss: 0.5071 - val_acc: 0.8944\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2224 - acc: 0.9026 - val_loss: 0.5095 - val_acc: 0.8803\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2219 - acc: 0.9066 - val_loss: 0.5173 - val_acc: 0.8944\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2223 - acc: 0.9026 - val_loss: 0.5266 - val_acc: 0.8451\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2235 - acc: 0.9066 - val_loss: 0.5136 - val_acc: 0.8944\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2198 - acc: 0.9105 - val_loss: 0.5175 - val_acc: 0.8873\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2181 - acc: 0.9205 - val_loss: 0.5296 - val_acc: 0.8873\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2190 - acc: 0.9105 - val_loss: 0.5291 - val_acc: 0.8873\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2165 - acc: 0.9125 - val_loss: 0.5337 - val_acc: 0.8944\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2169 - acc: 0.9145 - val_loss: 0.5441 - val_acc: 0.8803\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2194 - acc: 0.9105 - val_loss: 0.5405 - val_acc: 0.8873\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2177 - acc: 0.9125 - val_loss: 0.5482 - val_acc: 0.8873\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2112 - acc: 0.9125 - val_loss: 0.5478 - val_acc: 0.8873\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2113 - acc: 0.9165 - val_loss: 0.5535 - val_acc: 0.8944\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2129 - acc: 0.9165 - val_loss: 0.5512 - val_acc: 0.8944\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2114 - acc: 0.9205 - val_loss: 0.5759 - val_acc: 0.8451\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2092 - acc: 0.9225 - val_loss: 0.5753 - val_acc: 0.8662\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2076 - acc: 0.9185 - val_loss: 0.5762 - val_acc: 0.8592\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2065 - acc: 0.9165 - val_loss: 0.5702 - val_acc: 0.8451\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2197 - acc: 0.9066 - val_loss: 0.5755 - val_acc: 0.8451\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2051 - acc: 0.9165 - val_loss: 0.5724 - val_acc: 0.9014\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2126 - acc: 0.9225 - val_loss: 0.5746 - val_acc: 0.8944\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2059 - acc: 0.9205 - val_loss: 0.5992 - val_acc: 0.8451\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2077 - acc: 0.9205 - val_loss: 0.5801 - val_acc: 0.8873\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2080 - acc: 0.9145 - val_loss: 0.5963 - val_acc: 0.8944\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2020 - acc: 0.9165 - val_loss: 0.6009 - val_acc: 0.8873\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2016 - acc: 0.9225 - val_loss: 0.6161 - val_acc: 0.8662\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2020 - acc: 0.9185 - val_loss: 0.6093 - val_acc: 0.8521\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2030 - acc: 0.9185 - val_loss: 0.6322 - val_acc: 0.8310\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2046 - acc: 0.9066 - val_loss: 0.6173 - val_acc: 0.8803\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2032 - acc: 0.9145 - val_loss: 0.6290 - val_acc: 0.8662\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2001 - acc: 0.9165 - val_loss: 0.6245 - val_acc: 0.8944\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1992 - acc: 0.9165 - val_loss: 0.6353 - val_acc: 0.8873\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1984 - acc: 0.9205 - val_loss: 0.6360 - val_acc: 0.8662\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1978 - acc: 0.9205 - val_loss: 0.6371 - val_acc: 0.8662\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1986 - acc: 0.9165 - val_loss: 0.6397 - val_acc: 0.8592\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2016 - acc: 0.9165 - val_loss: 0.6547 - val_acc: 0.8521\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1976 - acc: 0.9125 - val_loss: 0.6415 - val_acc: 0.8944\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1970 - acc: 0.9205 - val_loss: 0.6480 - val_acc: 0.8592\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1949 - acc: 0.9145 - val_loss: 0.6540 - val_acc: 0.8944\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1948 - acc: 0.9185 - val_loss: 0.6556 - val_acc: 0.9014\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1961 - acc: 0.9185 - val_loss: 0.6505 - val_acc: 0.9014\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1986 - acc: 0.9205 - val_loss: 0.6667 - val_acc: 0.8380\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1996 - acc: 0.9105 - val_loss: 0.6704 - val_acc: 0.9014\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1934 - acc: 0.9165 - val_loss: 0.6717 - val_acc: 0.8451\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1950 - acc: 0.9145 - val_loss: 0.6757 - val_acc: 0.8662\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1936 - acc: 0.9185 - val_loss: 0.6776 - val_acc: 0.8944\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1922 - acc: 0.9165 - val_loss: 0.6746 - val_acc: 0.8732\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1941 - acc: 0.9165 - val_loss: 0.6939 - val_acc: 0.8732\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1916 - acc: 0.9145 - val_loss: 0.6898 - val_acc: 0.8944\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1948 - acc: 0.9145 - val_loss: 0.6925 - val_acc: 0.8521\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1945 - acc: 0.9165 - val_loss: 0.6937 - val_acc: 0.8803\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, \n",
    "                    epochs=NUM_OF_EPOCHS,\n",
    "                    verbose=1, validation_split=0.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb590856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3833 - acc: 0.8912\n",
      "Test Score: 0.3832702934741974\n",
      "Test Accuracy: 0.8911917209625244\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e218e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out saving the model in h5 file format\n",
    "# Ref: https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "# We have the model object that needs to be saved\n",
    "# It save text file with Hex numbers in HDF5 format in the current dir\n",
    "model.save('gliomadfClassifyModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "680054a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object representative_dataset at 0x0000023AC90F72C8>\n"
     ]
    }
   ],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "      data =  X_test\n",
    "      yield [data.astype(np.float32)]\n",
    "        \n",
    "print(representative_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6db3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_gliomadf_seq_model_keras_dir\\assets\n"
     ]
    }
   ],
   "source": [
    "# Converting a tf.Keras model to a TensorFlow Lite model.\n",
    "# It is preferred to use TFLiteConverter from saved model and then\n",
    "# Also provide representative dataset to train the converted TFLite model\n",
    "# Avoid calling the TFLite converter directly from model\n",
    "#converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tf.saved_model.save(model, \"saved_gliomadf_seq_model_keras_dir\")\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_gliomadf_seq_model_keras_dir\")\n",
    "\n",
    "# Though its size is not much, optimizer is used here to check whether it works on ESP32\n",
    "# if this is chosen, tf.lite.Optimize.OPTIMIZE_FOR_SIZE, the TFLite does not work on ESP32\n",
    "# Observed that even with Optimize.DEFAULT the TFLite model does not work on ESP32\n",
    "\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b39332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in TFlite format\n",
    "# It brings down the size\n",
    "with open('gliomadfClassifyModel.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "464f965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the inference on TFLITE model on Python ... here itself first\n",
    "# Let us now first try to run this tflinte model on Python itself\n",
    "# Ref: https://www.tensorflow.org/lite/guide/inference\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"gliomadfClassifyModel.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3d58f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_details:\n",
      " [{'name': 'serving_default_flatten_input:0', 'index': 0, 'shape': array([ 1, 23]), 'shape_signature': array([-1, 23]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "output_details:\n",
      " [{'name': 'StatefulPartitionedCall:0', 'index': 17, 'shape': array([1, 1]), 'shape_signature': array([-1,  1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print('input_details:\\n', input_details)\n",
    "print('output_details:\\n', output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed93d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ,-1.2084587209146778 ,1.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,-0.8732522345187961 ,\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "for i in X.iloc[100]:\n",
    "    print(i, end=' ,') # end = \"f, \"\n",
    "print(\"\\n\", y[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3159d9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ,-0.12325404319333862 ,0.0 ,0.0 ,0.0 ,1.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,-0.8732522345187961 ,\n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "for i in X.iloc[700]:\n",
    "    print(i,\",\", end='')\n",
    "print(\"\\n\", y[700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa3dc420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ,-0.05060969013389534 ,1.0 ,0.0 ,1.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,-0.19879566997801162 ,\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "for i in X.iloc[419]:\n",
    "    print(i,\",\", end='')\n",
    "print(\"\\n\", y[450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9729a80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ,-0.6349506704453851 ,1.0 ,1.0 ,1.0 ,1.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.1501174591035572 ,\n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "for i in X.iloc[723]:\n",
    "    print(i,\",\", end='')\n",
    "print(\"\\n\", y[723])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013354c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 0: [[0.41098578 0.73898537 0.93060314 0.92521167 0.38272335 0.91869346\n",
      "  0.27074674 0.5141972  0.43973506 0.82816205 0.72879192 0.40905345\n",
      "  0.39025372 0.64311485 0.59437164 0.10380482 0.42071384 0.99527167\n",
      "  0.73679525 0.08481944 0.01149438 0.50213834 0.80509158]]\n",
      "[[0.]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicted Output: [[1.8291357e-06]]\n",
      "\n",
      "Input 1:  [[0.0, -1.2084587209146778, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8732522345187961]]\n",
      "output1:\n",
      "[[0.]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicted Output:  [[0.00073058]]\n",
      "Actual Output: 0\n",
      "\n",
      "Input 2: [[0.0, -0.12325404319333862, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8732522345187961]]\n",
      "output2:\n",
      "[[0.921875]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicted output: [[0.91274124]]\n",
      "Actual Output: 1\n",
      "\n",
      "Input 3: [[0.0, -0.05060969013389534, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.19879566997801162]]\n",
      "output3:\n",
      "[[0.00390625]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicted output: [[0.00520247]]\n",
      "Actual Output: 0\n",
      "\n",
      "Input 4: [[0.0, -0.6349506704453851, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1501174591035572]]\n",
      "output4:\n",
      "[[0.68359375]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicted output: [[0.70112795]]\n",
      "Actual Output: 1\n"
     ]
    }
   ],
   "source": [
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "#print(input_shape)\n",
    "#print(type(X_test))\n",
    "#print(X_test.iloc[1])\n",
    "#print(X_test.iloc[0])\n",
    "input0_data = np.random.random_sample(input_shape)\n",
    "print(\"Input 0:\", input0_data)\n",
    "input0_data = np.array(input0_data, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input0_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output0_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output0_data)\n",
    "\n",
    "# Verify if the same data is given to the original model what is the output\n",
    "output0_data = model.predict(input0_data)\n",
    "print(\"Predicted Output:\", output0_data)\n",
    "\n",
    "# ['Gender', 'Age_at_diagnosis', 'IDH1', 'TP53', 'ATRX', 'PTEN', 'EGFR', 'CIC', 'MUC16', 'PIK3CA', 'NF1', 'PIK3R1', 'FUBP1', 'RB1', 'NOTCH1', 'BCOR', 'CSMD3', 'SMARCA4', 'GRIN2A', 'IDH2', 'FAT4', 'PDGFRA', 'Mutations']\n",
    "\n",
    "input1_data = [[0.0 ,-1.2084587209146778 ,1.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,-0.8732522345187961]]\n",
    "print(\"\\nInput 1: \", input1_data)\n",
    "input1_data = np.array(input1_data, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input1_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output1_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print('output1:')\n",
    "print(output1_data)\n",
    "\n",
    "# Verify if the same data is given to the original model what is the output\n",
    "output1_data = model.predict(input1_data)\n",
    "print(\"Predicted Output: \", output1_data)\n",
    "print(\"Actual Output: 0\")\n",
    "\n",
    "input2_data = [[0.0 ,-0.12325404319333862 ,0.0 ,0.0 ,0.0 ,1.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,-0.8732522345187961]]\n",
    "print(\"\\nInput 2:\", input2_data)\n",
    "input2_data = np.array(input2_data, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], tf.Variable(input2_data))\n",
    "\n",
    "interpreter.invoke()\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output2_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print('output2:')\n",
    "print(output2_data)\n",
    "\n",
    "# Verify if the same data is given to the original model what is the output\n",
    "output2_data = model.predict(input2_data)\n",
    "print(\"Predicted output:\", output2_data)\n",
    "print(\"Actual Output: 1\")\n",
    "\n",
    "input3_data = [[0.0 ,-0.05060969013389534 ,1.0 ,0.0 ,1.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,-0.19879566997801162]]\n",
    "print(\"\\nInput 3:\", input3_data)\n",
    "input3_data = np.array(input3_data, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], tf.Variable(input3_data))\n",
    "interpreter.invoke()\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output3_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print('output3:')\n",
    "print(output3_data)\n",
    "# Verify if the same data is given to the original model what is the output\n",
    "output3_data = model.predict(input3_data)\n",
    "print(\"Predicted output:\", output3_data)\n",
    "print(\"Actual Output: 0\")\n",
    "\n",
    "input4_data = [[0.0 ,-0.6349506704453851 ,1.0 ,1.0 ,1.0 ,1.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.1501174591035572]]\n",
    "print(\"\\nInput 4:\", input4_data)\n",
    "input4_data = np.array(input4_data, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], tf.Variable(input4_data))\n",
    "interpreter.invoke()\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output4_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print('output4:')\n",
    "print(output4_data)\n",
    "# Verify if the same data is given to the original model what is the output\n",
    "output4_data = model.predict(input4_data)\n",
    "print(\"Predicted output:\", output4_data)\n",
    "print(\"Actual Output: 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert some hex values into an array for C programming\n",
    "import time, sys\n",
    "\n",
    "# Function to convert some hex values into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "    c_str = \"\"\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += \"#define \" + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # c_str += \"/*\\n Reference from Prof. Mouli Sankaran \\n\"\n",
    "    c_str += \"/*\\n CAUTION: This is an auto generated file.\\n DO NOT EDIT OR MAKE ANY CHANGES TO IT.\\n\"\n",
    "\n",
    "# Time stamping of this model data in the generated file\n",
    "    localtime = time.asctime( time.localtime(time.time()) )\n",
    "    c_str += \" This model data was generated on \" + localtime+ '\\n\\n'\n",
    "    print(\"This model data was generated on:\", localtime)\n",
    "\n",
    "# Add information about the verisons of tools and packages used in generating this header file\n",
    "    c_str += \" Tools used:\\n Python:\" + str(sys.version) + \"\\n Numpy:\" + str(np.version.version) + \\\n",
    "          \"\\n TensorFlow:\" + str(sys.version) + \"\\n Keras: \"+ str(tf.keras.__version__) + \"\\n\\n\"\n",
    "    print(\"Tools used: Python:\", sys.version, \"\\n Numpy:\", np.version.version, \\\n",
    "          \"\\n TensorFlow:\", sys.version, \"\\n Keras: \", tf.keras.__version__, \"\\n\\n\")\n",
    "\n",
    "# Training details of the model\n",
    "    c_str += ' Model details are:\\n'\n",
    "    c_str += ' NUM_OF_EPOCHS = ' + str(NUM_OF_EPOCHS) + '\\n'\n",
    "    c_str += ' BATCH_SIZE    = ' + str(BATCH_SIZE) + '\\n*/\\n'\n",
    "    \n",
    "# Generate 'C' constants for the no. of nodes in each layer\n",
    "    c_str += '\\nconst int ' + 'DENSE1_SIZE' + ' = ' + str(DENSE1_SIZE) + ';\\n'\n",
    "    c_str +=   'const int ' + 'DENSE2_SIZE' + ' = ' + str(DENSE2_SIZE) + ';\\n'     \n",
    "    c_str +=   'const int ' + 'DENSE3_SIZE' + ' = ' + str(DENSE3_SIZE) + ';\\n' \n",
    "    \n",
    "    # Add array length at the top of the file\n",
    "    c_str += '\\nconst unsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'alignas(8) const unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data):\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formating so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "          hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "          hex_str += '\\n'\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n' + format(''.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38be992f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model data was generated on: Tue Nov  5 10:50:07 2024\n",
      "Tools used: Python: 3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)] \n",
      " Numpy: 1.21.5 \n",
      " TensorFlow: 3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)] \n",
      " Keras:  2.10.0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write TFLite model to a C source (or header) file\n",
    "with open(\"gliomadf_model_esp32\" + '.h', 'w') as file:\n",
    "  file.write(hex_to_c_array(tflite_model, \"gliomadf_model_esp32\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
